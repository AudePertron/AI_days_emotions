{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tuto_Emotions_Part1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AudePertron/AI_days_emotions/blob/main/Tuto_Emotions_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id7M4s_0dV2Y"
      },
      "source": [
        "# Reconnaissance des Emotions - 1/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V83wDBcdV2y"
      },
      "source": [
        "## - Exploration des données et création des Datasets, \n",
        "\n",
        "## - Entraînement du modèle d'identification des émotions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR9yHPlgdV24"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv_LfjmbdV28"
      },
      "source": [
        "- <a href='#1'>Prévisualisation des données</a>\n",
        "- <a href='#2'>Création des datasets d'apprentissage et de test</a>\n",
        "- <a href='#3'>Préparation des données</a>\n",
        "- <a href='#4'>Entrainement du modèle de reconnaissance des émotions</a>\n",
        "- <a href='#5'>Résultats</a> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGfmFOIhdV2-"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl9h9r9kdV3A"
      },
      "source": [
        "#préparation des imports (bibliothèques et librairies nécéssaires à l'éxécution du code)\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from keras.layers import Conv2D, experimental, Dense, MaxPooling2D, Flatten, Dropout\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "tf.random.set_seed(8449744397167270535)\n",
        "random.seed(8449744397167270535)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAy4kPv3dV3G"
      },
      "source": [
        "### <a id='1'>Prévisualisation des données</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OjiARaewGXd"
      },
      "source": [
        ">Si vous souhaitez exécuter ce notebook sur Google Colab, l'exécution des cellules suivantes vous permettra de cloner directement le repository Git sur Colab, et d'y extraire le ficher .zip de la data.\n",
        "\n",
        ">Vous pouvez bien sûr choisir d'exécuter les notebooks en local sur votre ordinateur, particulièrement si vous possédez un GPU. __Dans ce cas, il est inutile d'executer les 3 cellules suivantes.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raoGPn1vuO2E"
      },
      "source": [
        "!git clone https://github.com/AudePertron/AI_days_emotions.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4xjbmDGuK_A"
      },
      "source": [
        "!unzip /content/AI_days_emotions/data/emotions.zip -d /content/AI_days_emotions/data &> /dev/null\n",
        "print(\"Extraction des données terminée\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6UVFGGn0DqT"
      },
      "source": [
        "%cd /content/AI_days_emotions # on se place \"virtuellement\" dans le dossier créé"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzhSXX11eBOu"
      },
      "source": [
        "Notre dossier Data contient l'ensemble des données, séparées en données d'entraînement et données de test, elles-mêmes divisées en sous-dossiers par émotions. Vous pouvez visualiser l'arborescence des fichiers grâce à l'icône \"Files\" à gauche de votre écran, dnas le menu Colab.\n",
        "\n",
        "Chaque sous-dossier d'émotions contient des images en noir et blanc de 48*48 pixel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKrBaQ3_dV3H"
      },
      "source": [
        "#nous accédons aux données depuis le dossier dans lequel elles sont stockées\n",
        "tmp = os.listdir(\"./data/train\") \n",
        "\n",
        "print(\"La liste 'tmp' contient les noms de chacun des dossiers. Les voici :\")\n",
        "print(\" -\", \"\\n - \".join(tmp))\n",
        "\n",
        "#On prépare les labels (noms des émotions) en les récupérant à partir des noms de dossier.\n",
        "#On prépare d'abord un dictionnaire qui contiendra les numéros et les noms des classes \n",
        "#en fonction des noms des dossiers.\n",
        "LABELS ={} \n",
        "for clas, feeling in enumerate(tmp): # on itère sur la liste tmp pour récupérer ces labels.\n",
        "    LABELS[clas]=feeling\n",
        "\n",
        "NUM_CLASS = len(tmp) # le nombre de classes correspond au nombre de dossiers\n",
        "\n",
        "print(\"\\nIl y a donc\", NUM_CLASS, \"classes :\")\n",
        "print(LABELS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3eHSg27dV3N"
      },
      "source": [
        "#nous indiquons l'emplacement des images, et créons une liste d'entraînement et une liste de test vides\n",
        "\n",
        "trainset = []\n",
        "for i in tmp: # on itère sur tmp pour parcourir chacun des 4 dossiers\n",
        "    chemin = \"./data/train/\"+i\n",
        "    img = glob(\"%s/*.jpg\" %chemin) # la fonction glob permet de récupérer tous les fichiers d'un dossier\n",
        "    img = [os.path.abspath(x) for x in img]\n",
        "    trainset.append(img)\n",
        "\n",
        "testset = []\n",
        "for i in tmp:\n",
        "    chemin = \"./data/test/\"+i\n",
        "    img = glob(\"%s/*.jpg\" %chemin)\n",
        "    img = [os.path.abspath(x) for x in img]\n",
        "    testset.append(img)\n",
        "\n",
        "#Nous affichons le nombre d'images par catégorie :\n",
        "print(\"Nombre d'images de chaque classe dans le train set :\")\n",
        "print([(LABELS[i], len(trainset[i])) for i in range(len(trainset))])\n",
        "print(\"Et dans le test set :\")\n",
        "print([(LABELS[i], len(testset[i])) for i in range(len(testset))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9vHrBLLdV3Q"
      },
      "source": [
        "### <a id='2'>Création des datasets d'apprentissage et de test</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBojNF74gBXK"
      },
      "source": [
        "Nous créons les données d'entraînement. \n",
        "\n",
        "\n",
        "Notre objectif, plus communément appelé \"target\" et abrégé en \"y\" est le nom de l'émotion associée à chaque image, qu'on appellera \"label\". Il s'agit d'associer chaque y au X correspondant. Donc par exemple si `X[0]` correspond à une image d'une personne heureuse, `y[0]` sera égal à la variable \"happy\" (les noms de variables sont ici représentés par des chiffres, comme vu ci-dessus)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeWXIzkedV3S"
      },
      "source": [
        "# Nous créons la liste y_train (target sur les données d'entraînement)\n",
        "paths=[]\n",
        "y_train=[]\n",
        "\n",
        "for i in range(len(trainset)):\n",
        "    for j in range(len(trainset[i])):\n",
        "        paths.append(trainset[i][j])\n",
        "        y_train.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ46Isbog1wB"
      },
      "source": [
        "Les données que nous devons analyser, appelées \"features\" et abrègées en \"X\", sont les images. Chaque image est représenté par une matrice de taille 48x48 (hauteur * largeur de l'image en pixel), dont les chaque valeur peut varier entre 0 et 255 suivant la valeur du pixel en niveaux de gris (0 représentant le noir et 255 le blanc). Dans le cas d'images de couleur, il y aurait trois matrices (appelées canaux) pour chacune des valeurs RGB (rouge, vert, bleu).\n",
        "\n",
        "Pour charger ces images sous forme de matrices d'entiers entre 0 et 255, nous utilisons le module `imread` de la bibliothèque `OpenCV` (`cv2`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yensf8IZdV3c"
      },
      "source": [
        "X_train=[]\n",
        "for p in paths:\n",
        "    X_train.append(cv2.imread(p, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O67rNeMUhM_Z"
      },
      "source": [
        "Préparons ensuite des données de test, de la même façon que les données d'entraînement. Ces données nous serviront à la fin de cet exercice à évaluer notre modèle, c'est à dire à vérifier que notre modèle fonctionne bien sur de nouvelles images, sur lesquelles il n'a pas été entrainé, et donc qu'il ne \"connaît\" pas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXSPWcfMdV3d"
      },
      "source": [
        "paths2=[]\n",
        "y_test=[]\n",
        "\n",
        "for i in range(len(testset)):\n",
        "    for j in range(len(testset[i])):\n",
        "        paths2.append(testset[i][j])\n",
        "        y_test.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUBMIeyMdV3f"
      },
      "source": [
        "X_test=[]\n",
        "for p in paths2:\n",
        "    X_test.append(cv2.imread(p, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5j61ar7dV3f"
      },
      "source": [
        "### <a id='3'>Préparation des données</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlXvqG6OdV3g"
      },
      "source": [
        "#### Chargement des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIr-z6bbiXC5"
      },
      "source": [
        "Nous allons maintenant visualiser une image du dataset ainsi que son label pour vérifier que tout fonctionne correctement. Nous affichons de façon arbitraire l'image numéro 42, n'hésitez pas à modifier cette variable si vous souhaitez visualiser d'autres images du dataset.\n",
        "Nous en profitons pour afficher la dimension de l'image. La longueur de X_train indique le nombre d'images contenu dans le dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH1ocqKndV3i"
      },
      "source": [
        "plt.imshow(X_train[42], cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "print(f\"Il y a {len(X_train)} images de {X_train[42].shape} pixels dans le dataset.\\\n",
        " \\nVoici par exemple l'image n°42 :\")\n",
        "plt.title(LABELS[y_train[42]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP6QF4eBdV3j"
      },
      "source": [
        "#### Mélange des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX3-ud7wjc51"
      },
      "source": [
        "Nous allons maintenant mélanger les données (comme si l'on mélangeait des cartes avant une partie) car elles sont pour l'instant classées dans l'ordre des émotions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSn6IgUPdV3n"
      },
      "source": [
        "# pour l'entraînement\n",
        "# on crée un vecteur de nombres de allant de 0 à 1921 triés aléatoirement \n",
        "index = np.random.permutation([i for i in range(len(y_train))]) \n",
        "# on classe X_train et y_train suivant cet ordre aléatoire.\n",
        "X_train = np.asarray(X_train)[index] \n",
        "y_train = np.asarray(y_train)[index]\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQn3i5ridV3u"
      },
      "source": [
        "# pour les tests\n",
        "index2 = np.random.permutation([i for i in range(len(y_test))])\n",
        "\n",
        "X_test = np.asarray(X_test)[index2]\n",
        "y_test = np.asarray(y_test)[index2]\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OOg_V3C6qTL"
      },
      "source": [
        "Visualisons maintenant quelques-une de ces images, par exemple les 15 premières, en affichant le label, afin de vérifier notre dataset avant de commencer l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w38patmEdV3v"
      },
      "source": [
        "# visualisation\n",
        "plt.figure(figsize=(15,9))\n",
        "for i in range(15):\n",
        "    plt.subplot(3,5,i+1)\n",
        "    plt.imshow(np.uint8(X_train[i]), cmap='gray')\n",
        "    plt.title(LABELS[y_train[i]])\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On2wTgRgdV3w"
      },
      "source": [
        "#### Prétraitement en vue de l'entrainement avec un CNN Séquentiel "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG16bqacjz62"
      },
      "source": [
        "Il s'agit de transformer les données dans le format attendu par l'algorithme. \n",
        "\n",
        "Il faut d'abord normaliser les données, c'est à dire transformer toutes les valeurs de pixels afin qu'elles soient comprises entre 0 et 1. Comme la valeur maximale d'un pixel est de 255, il suffit de diviser les valeurs par ce nombre. \n",
        "\n",
        "Puis nous donnons la \"forme\" attendue à notre matrice. Nous précisons le nombre de canaux de nos images : \"1\" pour une image en noir et blanc (\"3\", correspondant aux canaux rouge, vert,  bleu, pour une image en couleur)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeH9f-kUdV3w"
      },
      "source": [
        "# standardisation, redimensionnement des features\n",
        "X_train = X_train.astype('float') / 255\n",
        "X_test = X_test.astype('float') / 255\n",
        "X_train = X_train.reshape(len(X_train),48,48,1)\n",
        "X_test = X_test.reshape(len(X_test),48,48,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltmKEsdhknCi"
      },
      "source": [
        "Nous encodons également nos valeurs-cibles (targets) y. Plutôt qu'avoir des valeurs entre 0 et 4 correspondant à un numéro arbitraire, nous le transformons en une liste de 0 et de 1, le 1 correspondant à l'émotion représentée.\n",
        "\n",
        "Par exemple, dans le cas de la joie, qui était auparavant égale à 3, nous aurons :\n",
        "- avant : `y=1`\n",
        "- après : `Y=[0,1,0,0]`\n",
        "\n",
        "ou pour la tristesse:\n",
        "- avant : `y=3`\n",
        "- après : `Y=[0,0,1,0]`\n",
        "et ainsi de suite.\n",
        "\n",
        "Cela permet d'éviter des biais car l'algorihtme pourrait accorder une plus grande importance à une émotion dont la valeur est plus élevée (considérer qu'une émotion avec pour valeur 4 est plus importante qu'une émotion avec une valeur 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfW3tAl1dV3x"
      },
      "source": [
        "# catégorisation des target\n",
        "y_test.reshape(len(y_test),1)\n",
        "y_train.reshape(len(y_train),1)\n",
        "Y_train = to_categorical(y_train, num_classes=NUM_CLASS).astype(int)\n",
        "Y_test = to_categorical(y_test, num_classes=NUM_CLASS).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FthUptd0dV3z"
      },
      "source": [
        "# vérificationpour un élément au hasard du set d'entrainement\n",
        "print(Y_train[42], y_train[42], LABELS[y_train[42]]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhotObL0dV30"
      },
      "source": [
        "# vérificationpour un élément au hasard du set de test\n",
        "print(Y_test[42], y_test[42], LABELS[y_test[42]]) #test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzVUiTo9dV33"
      },
      "source": [
        "### <a id='4'>Entrainement du modèle de reconnaissance des émotions</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sB17LhtdV37"
      },
      "source": [
        "#### Création du modèle séquentiel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr5d_nCBdV38"
      },
      "source": [
        "Nous allons maintenant appliquer un réseau de neurones convolutif sur nos données. Le temps d'entraînement peut être long, aussi, __pour gagner du temps, nous vous proposons de télécharger notre modèle préentraîné par la suite__, mais à nouveau, si en vous avez le temps, vous êtes libres d'éxécuter le modèle tel quel, voir même de jouer avec les paramètres pour le modifier !\n",
        "\n",
        "Ce modèle est composé de 15 couches de neurones. En modifiant ses paramètres vous pourriez obtenir des résultats très différents (peut-être meilleurs que les nôtres !).\n",
        "\n",
        "<br>\n",
        "\n",
        "Il vous faudra environ 10 à 15 minutes minutes pour entraîner le modèle proposé. Pendant ce temps, n'hésitez pas à nous poser vos questions ! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcNTtTZxdV3-"
      },
      "source": [
        "### nous avons construit le modèle suivant, c'est celui qui sera fourni pour la suite de l'exercice\n",
        "### Libre à vous de le modifier et de créer votre propre modèle !\n",
        "\n",
        "modelX = models.Sequential()\n",
        "\n",
        "modelX.add(Conv2D(64, 7, padding=\"same\", activation='relu', input_shape=(48,48,1)))\n",
        "modelX.add(MaxPooling2D(2))\n",
        "modelX.add(Dropout(0.5))\n",
        "modelX.add(Conv2D(64, 3, padding=\"same\", activation='relu'))\n",
        "modelX.add(MaxPooling2D(2))\n",
        "modelX.add(Dropout(0.5))\n",
        "modelX.add(Conv2D(128, 3, padding=\"same\", activation='relu'))\n",
        "modelX.add(MaxPooling2D(2))\n",
        "modelX.add(Dropout(0.5))\n",
        "modelX.add(Flatten())\n",
        "modelX.add(Dense(64, activation=\"relu\"))\n",
        "modelX.add(Dropout(0.25))\n",
        "modelX.add(Dense(32, activation=\"relu\"))\n",
        "modelX.add(Dropout(0.25))\n",
        "modelX.add(Dense(NUM_CLASS, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYYiXmrIdV3-"
      },
      "source": [
        "# compilation pour un premier entraînement avec l'optimizer Adamax\n",
        "modelX.compile(optimizer=optimizers.Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPW2HbeodV3_"
      },
      "source": [
        "### décommentez la ligne suivante si vous voulez entraîner votre propre modèle\n",
        "\n",
        "history = modelX.fit(X_train, Y_train, epochs=40, batch_size=5, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZsI4YTLdV3_"
      },
      "source": [
        "Au bout de nos 40 epochs, bien que le modèle semble converger, l'accuracy ne s'est pas tout à fait stabilisée. Cet indicateur nous informe sur la précision du modèle à faire de bonnes prédictions, plus on s'approche de 1, plus le modèle est performant. A chaque Epoch (itération), le modèle va (logiquement) parfaire son entrainement.\n",
        "\n",
        "Il semble que l'on puisse améliorer un peu ce résultat. Relançons l'entraînement pour 10 epoch, en affinant les hyperparamètres de l'optimizer Adamax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2yb8BQc9NX4"
      },
      "source": [
        "# second entrainement en affinant les parametres \n",
        "modelX.compile(optimizer=optimizers.Adamax(learning_rate=0.0001, beta_1=0.98, beta_2=0.98), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VkGC7GtXtUc"
      },
      "source": [
        "### décommentez la ligne suivante si vous voulez entraîner votre propre modèle\n",
        "\n",
        "history = modelX.fit(X_train, Y_train, epochs=10, batch_size=5, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhlBA7DuJuY1"
      },
      "source": [
        "### exectutez la ligne suivante si vous souhaitez enregistrer votre modèle personnalisé.\n",
        "\n",
        "modelX.save('My_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA7Sw0GNnojJ"
      },
      "source": [
        "Grâce au deuxième entrainement, nous parvenons à un score stable autour de  72%. Dans l'absolu, ce score peut ne pas paraître excellent, mais par rapport aux données utilisées c'est un score honorable.\n",
        "\n",
        "Vous pouvez essayer de relancer ce modèle (nous vous conseillons de le faire sur Colab ou avec un GPU) en jouant sur l'optimizer et ses hyperparamètre, ou même en modifiant le nombre de couches et de neurones par couches dans le modèle, vous obtiendrez peut-être un meilleur score que nous !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85cZbrktdV4D"
      },
      "source": [
        "#### Validation sur la base de données de test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rshljthloKrX"
      },
      "source": [
        "Nous allons mainteant évaluer nos résulats grâce à nos données de test. Dans la cellule suivante, nous vous proposons de charger notre modèle pré-entrainé, si vous n'avez pas exécuté les lignes précédentes. \n",
        "\n",
        "Vous pouvez également charger le modèle que vous venez d'enregistrer, soit avec les paramètres que nous avons proposé soit avec vos propres paramètres. \n",
        "\n",
        "Décommentez la ligne qui concerne le chargement que vous voulez effectuer (ou bien continuez avec le modèle que vous venez d'entraîner)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igy5-FSWdV4E"
      },
      "source": [
        "\n",
        "#### Pour charger le modèle pré-entrainé :\n",
        "# modelX = models.load_model('ModelX') \n",
        "\n",
        "#### OU \n",
        "#### Pour charger le modèle que vous venez d'enregistrer :\n",
        "modelX = models.load_model('My_model') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiGbt9WrdV4F"
      },
      "source": [
        "len(X_test)\n",
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HO9XCS3pUSR"
      },
      "source": [
        "Nous examinons les prédictions de notre algorithme sur les données de test, et les comparons à leur valeur réelle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BGTSXLNdV4N"
      },
      "source": [
        "Y_pred = modelX.predict(X_test) # on demande à notre modèle de réaliser les prédictions sur la base de test."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-VGG4gWdV4O"
      },
      "source": [
        "y_pred=[]\n",
        "for y in Y_pred:\n",
        "    y_pred.append(np.argmax(y))\n",
        "# on décode les prédictions, afin de passer du format Y=[0,0,1,0] au format y=2, à l'inverse ce qu'on a fait plus haut. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbYMS57UpqwT"
      },
      "source": [
        "L'utilisation d'une matrice de confusion nous montrera _où_ l'algorithme se \"trompe\". \n",
        "\n",
        "Dans l'idéal, toutes les valeurs devraient être sur la diagonale haut-gauche / bas-droite. Les valeurs qui se situent sur cette diagonale sont les images correctement identifiées. \n",
        "Les autres sont mal identifiées : les valeurs réelles se situent sur l'axe des ordonnées, et les valeurs prédites sur les abscisses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD5dN92YdV4P",
        "scrolled": true
      },
      "source": [
        "cf_matrix = confusion_matrix(y_test, y_pred) \n",
        "# le module metrics.confusion_matrix est disponible dans la bibliothèque scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YinsTYcKQbLs"
      },
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(cf_matrix, cmap=\"Purples\")\n",
        "for (i, j), z in np.ndenumerate(cf_matrix):\n",
        "    plt.text(j, i, z, ha='center', va='center', bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))\n",
        "plt.xlabel(\"valeurs prédites\")\n",
        "plt.xticks(ticks =[i for i in range(4)], labels=[LABELS[i] for i in range(4)])\n",
        "plt.ylabel(\"valeurs réelles\")\n",
        "plt.yticks(ticks =[i for i in range(4)], labels=[LABELS[i] for i in range(4)])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru3V3rZbdV4R"
      },
      "source": [
        "### <a id='5'>Résultats</a>\n",
        "\n",
        "La matrice de confusion nous montre que le modèle semble avoir plus de mal à reconnaître certains sentiments que d'autres. \n",
        "\n",
        "Si l'on regarde les images de la colère, par exemple : un peu plus de la moitié d'entre elles ont dû être correctement identifiées, mais presque toutes les autres ont probablement été prises pour des expressions de la tristesse. Il y a d'ailleurs aussi beaucoup de mauvaises interprétations du sentiment de tristesse. \n",
        "\n",
        "Pas terrible... Qu'en pensez-vous ? \n",
        "Maintenant, allez regarder les images du dataset : à l'oeil nu, auriez-vous pu faire mieux ? ;)\n",
        "\n",
        "Car en effet, une bonne part de la réussite d'un modèle d'intelligence artificielle réside dans la collecte et la préparation des données. La recherche des paramètres optimaux (nombre de couches de convolution, optimisateur utilisé, taux d'apprentissage, fonction de perte, etc.) ne fait pas tout. Il faut d'abord réunir un dataset cohérent, correctement labellisé et préparé, avant d'entreprendre toute tâche de machine-learning ou de deep_learning."
      ]
    }
  ]
}